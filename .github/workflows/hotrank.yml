name: Daily HotNews Smart Builder

on:
  schedule:
    - cron: '0 0 * * *'          # 每天 08:00 北京
  workflow_dispatch:

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests openai

      - name: Run smart crawler
        run: |
          cat > grab_smart.py << 'PY'
          import requests, re, json, datetime, os, openai, time
          openai.api_key = os.getenv("OPENAI_API_KEY")

          today = datetime.date.today().strftime("%Y-%m-%d")
          URLS = {
            "微博":  f"https://raw.githubusercontent.com/SnailDev/weibo-hot-hub/main/archives/{today}.md",
            "知乎":  f"https://raw.githubusercontent.com/SnailDev/zhihu-hot-hub/main/archives/{today}.md",
            "微信":  f"https://raw.githubusercontent.com/SnailDev/wechat-hot-hub/main/archives/{today}.md",
            "头条":  f"https://raw.githubusercontent.com/SnailDev/toutiao-hot-hub/main/archives/{today}.md",
            "抖音":  f"https://raw.githubusercontent.com/SnailDev/douyin-hot-hub/main/archives/{today}.md"
          }
          pat = re.compile(r'\d+\.\s*\[(.+?)\]\((https?://[^)]+)\)')
          items = []

          def gen_summary(title):
              prompt = f"用一句话总结并判断该事件和普通人生活关联度（高/中/低）：《{title}》"
              for _ in range(3):
                  try:
                      rsp = openai.ChatCompletion.create(
                        model="gpt-4o-mini",
                        messages=[{"role":"user","content":prompt}],
                        temperature=0.7, max_tokens=60)
                      text = rsp.choices[0].message.content.strip()
                      if "：" in text:
                          relevance, summary = text.split("：",1)
                      else:
                          relevance, summary = "medium", text
                      return summary[:120], relevance.lower()
                  except Exception as e:
                      time.sleep(2)
              return "", "low"

          for src, url in URLS.items():
              try:
                  md = requests.get(url, timeout=20).text
                  for idx,(title, link) in enumerate(pat.findall(md)[:20],1):
                      summary, rel = gen_summary(title)
                      priority = 1 if rel=="high" else 2 if rel=="medium" else 3
                      items.append({"title":title.strip(),
                                    "link":link.strip(),
                                    "summary":summary,
                                    "date": today,
                                    "relevance": rel,
                                    "priority": priority})
              except Exception as e:
                  print(f"[WARN] {src} 获取失败: {e}")

          items.sort(key=lambda x: x["priority"])
          out = f"hotnews_smart_{today}.json"
          with open(out,"w",encoding="utf-8") as f:
              json.dump(items,f,ensure_ascii=False,indent=2)
          print(f"Summary OK ▶ {len(items)} 条写入 {out}")
          PY
          python grab_smart.py

      - name: Commit & Push
        run: |
          git config --global user.name  'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add hotnews_smart_*.json
          git commit -m "smart hotnews $(date +'%F')" || echo "No changes"
          git push
